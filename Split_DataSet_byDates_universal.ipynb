{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move or copy files?\n",
    "copy_or_move = 'copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5a016b-3c91-465e-a9e6-7de4766d8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set path to input director containing all files:\n",
    "input_dir = 'D:/InsectSound1000'\n",
    "\n",
    "# Set path to output directory:\n",
    "base_dir = 'D:/InsectSound1000'\n",
    "\n",
    "\n",
    "labels = ['Coccinella',\n",
    "          'Episyrphus',\n",
    "          'Bombus',\n",
    "          'Rhaphigaster',\n",
    "          'Bradysia',\n",
    "          'Aphidoletes', \n",
    "          'Halyomorpha',\n",
    "          'Nezara',\n",
    "          'Palomena',\n",
    "          'Trialeurodes',\n",
    "          'Myzus',\n",
    "          'Tuta']\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c547a85f-5e66-4039-94d7-0d7ad0dad1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split directories:\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df14639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 files found for Coccinella\n",
      "20230418 70\n",
      "20230420 68\n",
      "20230419 48\n",
      "20230425 26\n",
      "20230424 12\n",
      "108 68 48\n",
      "48.21% 30.36% 21.43%\n",
      "\n",
      "868 files found for Episyrphus\n",
      "20230515 653\n",
      "20230612 155\n",
      "20230511 60\n",
      "653 155 60\n",
      "75.23% 17.86% 6.91%\n",
      "\n",
      "6405 files found for Bombus\n",
      "20230510 2353\n",
      "20230427 2069\n",
      "20230509 1983\n",
      "2353 2069 1983\n",
      "36.74% 32.3% 30.96%\n",
      "\n",
      "733 files found for Rhaphigaster\n",
      "20230925 211\n",
      "20230920 184\n",
      "20231004 123\n",
      "20230918 103\n",
      "20231005 58\n",
      "20230919 48\n",
      "20230914 6\n",
      "426 184 123\n",
      "58.12% 25.1% 16.78%\n",
      "\n",
      "113 files found for Bradysia\n",
      "20220329 57\n",
      "20220331 37\n",
      "20220330 19\n",
      "57 37 19\n",
      "50.44% 32.74% 16.81%\n",
      "\n",
      "267 files found for Aphidoletes\n",
      "20220504 110\n",
      "20220503 67\n",
      "20220324 33\n",
      "20220502 31\n",
      "20220323 26\n",
      "141 67 59\n",
      "52.81% 25.09% 22.1%\n",
      "\n",
      "735 files found for Halyomorpha\n",
      "20220601 215\n",
      "20220530 160\n",
      "20220531 108\n",
      "20220421 104\n",
      "20220420 64\n",
      "20220524 47\n",
      "20220425 37\n",
      "430 160 145\n",
      "58.5% 21.77% 19.73%\n",
      "\n",
      "896 files found for Nezara\n",
      "20220511 681\n",
      "20220512 90\n",
      "20220602 65\n",
      "20220614 32\n",
      "20220523 28\n",
      "681 90 125\n",
      "76.0% 10.04% 13.95%\n",
      "\n",
      "1282 files found for Palomena\n",
      "20220907 833\n",
      "20220908 188\n",
      "20220811 115\n",
      "20220817 41\n",
      "20220816 37\n",
      "20220815 35\n",
      "20220810 33\n",
      "833 229 220\n",
      "64.98% 17.86% 17.16%\n",
      "\n",
      "296 files found for Trialeurodes\n",
      "20220913 128\n",
      "20220914 69\n",
      "20220719 32\n",
      "20220912 28\n",
      "20220720 23\n",
      "20220922 16\n",
      "179 69 48\n",
      "60.47% 23.31% 16.22%\n",
      "\n",
      "155 files found for Myzus\n",
      "20220328 66\n",
      "20220630 47\n",
      "20220705 22\n",
      "20220706 20\n",
      "66 47 42\n",
      "42.58% 30.32% 27.1%\n",
      "\n",
      "160 files found for Tuta\n",
      "20220707 35\n",
      "20220712 30\n",
      "20220713 30\n",
      "20220714 24\n",
      "20220725 22\n",
      "20220628 10\n",
      "20220711 9\n",
      "100 30 30\n",
      "62.5% 18.75% 18.75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from fetchfiles import fetchfiles\n",
    "\n",
    "for label in labels:\n",
    "    this_label_files = fetchfiles(input_dir, label)\n",
    "    print(str(len(this_label_files)) + ' files found for ' + label)\n",
    "\n",
    "    # get all recording dates:\n",
    "    dates = []\n",
    "    for file in this_label_files:\n",
    "        _, fname = os.path.split(file)\n",
    "        date = fname[:8]\n",
    "        if date not in dates:\n",
    "            dates.append(date)\n",
    "\n",
    "    # use list compression to build a dates dictionary for this label:\n",
    "    dates_dict = {}\n",
    "    for date in dates:\n",
    "        dates_dict[date] = [file for file in this_label_files if date in file]\n",
    "        \n",
    "    # sort by lenght of list:\n",
    "    dates_dict = dict(sorted(dates_dict.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "    # print sorted dict:\n",
    "    for key, value in dates_dict.items():\n",
    "        print(key, len(value))\n",
    "    \n",
    "    # now let's split the files into train, validation and test sets:\n",
    "    # make sure dates don't overlap between sets:\n",
    "    train_files = []\n",
    "    validation_files = []\n",
    "    test_files = []\n",
    "    \n",
    "    if len(dates_dict) < 3:\n",
    "        print('Not enough dates to split the data into train, validation and test sets.')\n",
    "        break\n",
    "    else:\n",
    "        # biggest date goes to train, secound biggest to validation, thrid biggest to test\n",
    "        # rest gets added to train:\n",
    "         # put the big files in frist:\n",
    "        train_files.extend(dates_dict.pop(next(iter(dates_dict))))\n",
    "        validation_files.extend(dates_dict.pop(next(iter(dates_dict))))\n",
    "        test_files.extend(dates_dict.pop(next(iter(dates_dict))))\n",
    "        \n",
    "        while len(dates_dict) > 0:\n",
    "        \n",
    "            # but, make sure we have at least 1000 sample in the test set:\n",
    "            while(len(test_files)/len(this_label_files)) < 0.15:\n",
    "                if len(dates_dict) == 0:\n",
    "                    break\n",
    "                # add the smallest date to test set:\n",
    "                test_files.extend(dates_dict.pop(next(reversed(dates_dict))))\n",
    "                \n",
    "            # but, make sure validation set is not to small:\n",
    "            while (len(validation_files)/len(this_label_files)) < 0.15:\n",
    "                if len(dates_dict) == 0:\n",
    "                    break\n",
    "                # add the smallest left date to validation set:\n",
    "                validation_files.extend(dates_dict.pop(next(reversed(dates_dict))))\n",
    "            \n",
    "            # add the rest to train set:\n",
    "            if len(dates_dict) > 0:\n",
    "                train_files.extend(dates_dict.pop(next(reversed(dates_dict))))\n",
    "        \n",
    "    print('%s %s %s' % (str(len(train_files)), str(len(validation_files)), str(len(test_files))))\n",
    "    print(str(round(len(train_files)/len(this_label_files)*100, 2)) + '% ' \n",
    "          + str(round(len(validation_files)/len(this_label_files)*100, 2)) + '% ' \n",
    "          + str(round(len(test_files)/len(this_label_files)*100, 2)) + '%')\n",
    "    print()  \n",
    "\n",
    "    # now let's copy the files to the new directories:\n",
    "    for files, dst_folder in zip([train_files, validation_files, test_files], [train_dir, validation_dir, test_dir]):\n",
    "        for file in files:\n",
    "            dontneedthis, fname = os.path.split(file)\n",
    "            src = file\n",
    "            dst = os.path.join(dst_folder, fname)\n",
    "            if copy_or_move == 'move':\n",
    "                shutil.move(src, dst)\n",
    "            elif copy_or_move == 'copy':\n",
    "                shutil.copy(src, dst)     \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43036eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Branding_SignalProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
